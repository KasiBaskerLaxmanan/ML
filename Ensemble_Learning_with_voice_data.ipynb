{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Ensemble Learning with voice data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RrKjV8-GJ9H"
      },
      "source": [
        "# Welcome!\n",
        "\n",
        "In this lab section we will be utilizing the data from https://www.kaggle.com/primaryobjects/voicegender#\n",
        "\n",
        "Do note that there is some tricky ethical stuff here considering that the voice of Philippe Jaroussky could be classified as Female (Countertenor) while the voice of Nathalie Stutzmann might be classified as Male (Contralto).\n",
        "\n",
        "\n",
        "For the exercise we will be following my framework TACT which is to Target, Arrange, Compose, and Transmit.\n",
        "\n",
        "Read more about it here: tactmethod.com\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGds7xjKGJ9J"
      },
      "source": [
        "# What is our target?\n",
        "\n",
        "In general we want to achieve a highly precise classifier utilizing voice data (as close to 100% as possible).\n",
        "\n",
        "How do we go about doing this? There are a few directions to go in this exercise either we do feature selection, feature transformation, or ensemble learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfNqyoEDGJ9K"
      },
      "source": [
        "# Arrange data\n",
        "\n",
        "The first step is to load up the data\n",
        "\n",
        "Also it's good to note what exactly is in it:\n",
        "\n",
        "## The Dataset\n",
        "The following acoustic properties of each voice are measured and included within the CSV:\n",
        "\n",
        "* meanfreq: mean frequency (in kHz)\n",
        "* sd: standard deviation of frequency\n",
        "* median: median frequency (in kHz)\n",
        "* Q25: first quantile (in kHz)\n",
        "* Q75: third quantile (in kHz)\n",
        "* IQR: interquantile range (in kHz)\n",
        "* skew: skewness (see note in specprop description)\n",
        "* kurt: kurtosis (see note in specprop description)\n",
        "* sp.ent: spectral entropy\n",
        "* sfm: spectral flatness\n",
        "* mode: mode frequency\n",
        "* centroid: frequency centroid (see specprop)\n",
        "* peakf: peak frequency (frequency with highest energy)\n",
        "* meanfun: average of fundamental frequency measured across acoustic signal\n",
        "* minfun: minimum fundamental frequency measured across acoustic signal\n",
        "* maxfun: maximum fundamental frequency measured across acoustic signal\n",
        "* meandom: average of dominant frequency measured across acoustic signal\n",
        "* mindom: minimum of dominant frequency measured across acoustic signal\n",
        "* maxdom: maximum of dominant frequency measured across acoustic signal\n",
        "* dfrange: range of dominant frequency measured across acoustic signal\n",
        "* modindx: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range\n",
        "* label: male or female (Note that we don't want to classify on this!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sm7Nhs4GJ9L"
      },
      "source": [
        "#!pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/voice.csv') \n",
        "\n",
        "y = df['label']\n",
        "X = df[set(df.columns) - set(['label'])]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpc926DxGJ-A",
        "outputId": "6a494814-4654-4a10-b088-b8a86b6dc220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!more ~/Documents/pyMattHarrison/Ensemble_DeepLearning/practical-machine-learning-master/data/voice.csv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "more: stat of /root/Documents/pyMattHarrison/Ensemble_DeepLearning/practical-machine-learning-master/data/voice.csv failed: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWTZPf1ZIgta",
        "outputId": "d4013ab3-f562-4c3d-ea6e-a71df31bff67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df.info()\n",
        "df.describe().T"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3168 entries, 0 to 3167\n",
            "Data columns (total 21 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   meanfreq  3168 non-null   float64\n",
            " 1   sd        3168 non-null   float64\n",
            " 2   median    3168 non-null   float64\n",
            " 3   Q25       3168 non-null   float64\n",
            " 4   Q75       3168 non-null   float64\n",
            " 5   IQR       3168 non-null   float64\n",
            " 6   skew      3168 non-null   float64\n",
            " 7   kurt      3168 non-null   float64\n",
            " 8   sp.ent    3168 non-null   float64\n",
            " 9   sfm       3168 non-null   float64\n",
            " 10  mode      3168 non-null   float64\n",
            " 11  centroid  3168 non-null   float64\n",
            " 12  meanfun   3168 non-null   float64\n",
            " 13  minfun    3168 non-null   float64\n",
            " 14  maxfun    3168 non-null   float64\n",
            " 15  meandom   3168 non-null   float64\n",
            " 16  mindom    3168 non-null   float64\n",
            " 17  maxdom    3168 non-null   float64\n",
            " 18  dfrange   3168 non-null   float64\n",
            " 19  modindx   3168 non-null   float64\n",
            " 20  label     3168 non-null   object \n",
            "dtypes: float64(20), object(1)\n",
            "memory usage: 519.9+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>meanfreq</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.180907</td>\n",
              "      <td>0.029918</td>\n",
              "      <td>0.039363</td>\n",
              "      <td>0.163662</td>\n",
              "      <td>0.184838</td>\n",
              "      <td>0.199146</td>\n",
              "      <td>0.251124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sd</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.057126</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.018363</td>\n",
              "      <td>0.041954</td>\n",
              "      <td>0.059155</td>\n",
              "      <td>0.067020</td>\n",
              "      <td>0.115273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.185621</td>\n",
              "      <td>0.036360</td>\n",
              "      <td>0.010975</td>\n",
              "      <td>0.169593</td>\n",
              "      <td>0.190032</td>\n",
              "      <td>0.210618</td>\n",
              "      <td>0.261224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q25</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.140456</td>\n",
              "      <td>0.048680</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.111087</td>\n",
              "      <td>0.140286</td>\n",
              "      <td>0.175939</td>\n",
              "      <td>0.247347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q75</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.224765</td>\n",
              "      <td>0.023639</td>\n",
              "      <td>0.042946</td>\n",
              "      <td>0.208747</td>\n",
              "      <td>0.225684</td>\n",
              "      <td>0.243660</td>\n",
              "      <td>0.273469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IQR</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.084309</td>\n",
              "      <td>0.042783</td>\n",
              "      <td>0.014558</td>\n",
              "      <td>0.042560</td>\n",
              "      <td>0.094280</td>\n",
              "      <td>0.114175</td>\n",
              "      <td>0.252225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skew</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>3.140168</td>\n",
              "      <td>4.240529</td>\n",
              "      <td>0.141735</td>\n",
              "      <td>1.649569</td>\n",
              "      <td>2.197101</td>\n",
              "      <td>2.931694</td>\n",
              "      <td>34.725453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kurt</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>36.568461</td>\n",
              "      <td>134.928661</td>\n",
              "      <td>2.068455</td>\n",
              "      <td>5.669547</td>\n",
              "      <td>8.318463</td>\n",
              "      <td>13.648905</td>\n",
              "      <td>1309.612887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sp.ent</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.895127</td>\n",
              "      <td>0.044980</td>\n",
              "      <td>0.738651</td>\n",
              "      <td>0.861811</td>\n",
              "      <td>0.901767</td>\n",
              "      <td>0.928713</td>\n",
              "      <td>0.981997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sfm</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.408216</td>\n",
              "      <td>0.177521</td>\n",
              "      <td>0.036876</td>\n",
              "      <td>0.258041</td>\n",
              "      <td>0.396335</td>\n",
              "      <td>0.533676</td>\n",
              "      <td>0.842936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mode</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.165282</td>\n",
              "      <td>0.077203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118016</td>\n",
              "      <td>0.186599</td>\n",
              "      <td>0.221104</td>\n",
              "      <td>0.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>centroid</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.180907</td>\n",
              "      <td>0.029918</td>\n",
              "      <td>0.039363</td>\n",
              "      <td>0.163662</td>\n",
              "      <td>0.184838</td>\n",
              "      <td>0.199146</td>\n",
              "      <td>0.251124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meanfun</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.142807</td>\n",
              "      <td>0.032304</td>\n",
              "      <td>0.055565</td>\n",
              "      <td>0.116998</td>\n",
              "      <td>0.140519</td>\n",
              "      <td>0.169581</td>\n",
              "      <td>0.237636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minfun</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.036802</td>\n",
              "      <td>0.019220</td>\n",
              "      <td>0.009775</td>\n",
              "      <td>0.018223</td>\n",
              "      <td>0.046110</td>\n",
              "      <td>0.047904</td>\n",
              "      <td>0.204082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maxfun</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.258842</td>\n",
              "      <td>0.030077</td>\n",
              "      <td>0.103093</td>\n",
              "      <td>0.253968</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.277457</td>\n",
              "      <td>0.279114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meandom</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.829211</td>\n",
              "      <td>0.525205</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.419828</td>\n",
              "      <td>0.765795</td>\n",
              "      <td>1.177166</td>\n",
              "      <td>2.957682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mindom</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.052647</td>\n",
              "      <td>0.063299</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.023438</td>\n",
              "      <td>0.070312</td>\n",
              "      <td>0.458984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maxdom</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>5.047277</td>\n",
              "      <td>3.521157</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>2.070312</td>\n",
              "      <td>4.992188</td>\n",
              "      <td>7.007812</td>\n",
              "      <td>21.867188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dfrange</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>4.994630</td>\n",
              "      <td>3.520039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.044922</td>\n",
              "      <td>4.945312</td>\n",
              "      <td>6.992188</td>\n",
              "      <td>21.843750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modindx</th>\n",
              "      <td>3168.0</td>\n",
              "      <td>0.173752</td>\n",
              "      <td>0.119454</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.099766</td>\n",
              "      <td>0.139357</td>\n",
              "      <td>0.209183</td>\n",
              "      <td>0.932374</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count       mean         std  ...       50%        75%          max\n",
              "meanfreq  3168.0   0.180907    0.029918  ...  0.184838   0.199146     0.251124\n",
              "sd        3168.0   0.057126    0.016652  ...  0.059155   0.067020     0.115273\n",
              "median    3168.0   0.185621    0.036360  ...  0.190032   0.210618     0.261224\n",
              "Q25       3168.0   0.140456    0.048680  ...  0.140286   0.175939     0.247347\n",
              "Q75       3168.0   0.224765    0.023639  ...  0.225684   0.243660     0.273469\n",
              "IQR       3168.0   0.084309    0.042783  ...  0.094280   0.114175     0.252225\n",
              "skew      3168.0   3.140168    4.240529  ...  2.197101   2.931694    34.725453\n",
              "kurt      3168.0  36.568461  134.928661  ...  8.318463  13.648905  1309.612887\n",
              "sp.ent    3168.0   0.895127    0.044980  ...  0.901767   0.928713     0.981997\n",
              "sfm       3168.0   0.408216    0.177521  ...  0.396335   0.533676     0.842936\n",
              "mode      3168.0   0.165282    0.077203  ...  0.186599   0.221104     0.280000\n",
              "centroid  3168.0   0.180907    0.029918  ...  0.184838   0.199146     0.251124\n",
              "meanfun   3168.0   0.142807    0.032304  ...  0.140519   0.169581     0.237636\n",
              "minfun    3168.0   0.036802    0.019220  ...  0.046110   0.047904     0.204082\n",
              "maxfun    3168.0   0.258842    0.030077  ...  0.271186   0.277457     0.279114\n",
              "meandom   3168.0   0.829211    0.525205  ...  0.765795   1.177166     2.957682\n",
              "mindom    3168.0   0.052647    0.063299  ...  0.023438   0.070312     0.458984\n",
              "maxdom    3168.0   5.047277    3.521157  ...  4.992188   7.007812    21.867188\n",
              "dfrange   3168.0   4.994630    3.520039  ...  4.945312   6.992188    21.843750\n",
              "modindx   3168.0   0.173752    0.119454  ...  0.139357   0.209183     0.932374\n",
              "\n",
              "[20 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LK9dLgCGJ-G"
      },
      "source": [
        "# Strawman Model\n",
        "\n",
        "Always always start with a baseline model. What is a decent enough model and what isn't?\n",
        "\n",
        "KNN and Naive Bayesian models are pretty easy to utilize and generally get someone started\n",
        "\n",
        "Can we make this better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptd_lDcjGJ-H",
        "outputId": "0824cf48-3153-4ff7-b0a1-1b752dab8854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# K-Nearest Neighbors is usually where the introduction class leaves off\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "nb = BernoulliNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "print(\"KNN\")\n",
        "print(classification_report(knn.predict(X_test), y_test))\n",
        "print(\"Naive Bayesian\")\n",
        "print(classification_report(nb.predict(X_test), y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.69      0.74      0.71       363\n",
            "        male       0.76      0.72      0.74       429\n",
            "\n",
            "    accuracy                           0.73       792\n",
            "   macro avg       0.73      0.73      0.73       792\n",
            "weighted avg       0.73      0.73      0.73       792\n",
            "\n",
            "Naive Bayesian\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.94      0.51      0.66       724\n",
            "        male       0.11      0.68      0.19        68\n",
            "\n",
            "    accuracy                           0.52       792\n",
            "   macro avg       0.53      0.59      0.43       792\n",
            "weighted avg       0.87      0.52      0.62       792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2HcgAwKGJ-L"
      },
      "source": [
        "# Thoughts?\n",
        "\n",
        "What are your thoughts on the above classification report. Note that when we look at KNN the precision is around 70% which is ok, but not great. Can we do better by selecting better features? OR transforming features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPGyYCvhGJ-L"
      },
      "source": [
        "# Feature Selection\n",
        "\n",
        "Looking at the data what is a good feature?\n",
        "\n",
        "In general there are a few directions to go here. We can look at Feature Importance by running this through a classifier, or we could look at variance thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l20HgIL8GJ-M",
        "outputId": "d1f2143d-4795-4adb-f1c6-a73536c3b84b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# If we take the data and fit it into a small support vector machine\n",
        "# We can figure out what has the highest weighting and then turn it into a new transformer\n",
        "# SelectFromModel does the heavy lifting\n",
        "# l1 is more contrained but can use l2 as well.\n",
        "\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l2\", dual=False).fit(X, y)\n",
        "model = SelectFromModel(lsvc, prefit=True)\n",
        "X_new = model.transform(X)\n",
        "print(X_new.shape)\n",
        "print(X_new[10:])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3168, 5)\n",
            "[[0.73369288 0.96524914 0.10142993 0.08889398 0.11530982]\n",
            " [0.75204201 0.96600378 0.08731383 0.10419932 0.11542553]\n",
            " [0.73614996 0.96351353 0.0831449  0.09264402 0.12608187]\n",
            " ...\n",
            " [0.65419636 0.94685426 0.03342387 0.20991768 0.19093638]\n",
            " [0.67546972 0.95043638 0.0435081  0.172375   0.1764347 ]\n",
            " [0.60152881 0.93882942 0.0700715  0.18560693 0.18075587]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI18R8w7GJ-S",
        "outputId": "a1e0206d-32f3-4b09-8db5-48c5fedb86ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn.fit(model.transform(X_train), y_train)\n",
        "nb = BernoulliNB()\n",
        "nb.fit(model.transform(X_train), y_train)\n",
        "\n",
        "print(\"KNN\")\n",
        "print(classification_report(knn.predict(model.transform(X_test)), y_test))\n",
        "print(\"Naive Bayesian\")\n",
        "print(classification_report(nb.predict(model.transform(X_test)), y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.69      0.71      0.70       375\n",
            "        male       0.74      0.71      0.72       417\n",
            "\n",
            "    accuracy                           0.71       792\n",
            "   macro avg       0.71      0.71      0.71       792\n",
            "weighted avg       0.71      0.71      0.71       792\n",
            "\n",
            "Naive Bayesian\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       1.00      0.49      0.66       792\n",
            "        male       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.49       792\n",
            "   macro avg       0.50      0.24      0.33       792\n",
            "weighted avg       1.00      0.49      0.66       792\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swMkYOYqGJ-V",
        "outputId": "20c59640-31bd-48ff-acbf-fc0302966025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "# Tree based models can also determine what is most indicative by looking at feature importance\n",
        "# Feature importances are usually what are the attributes that yield the biggest change to the outcome\n",
        "\n",
        "clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = clf.fit(X, y)\n",
        "model = SelectFromModel(clf, prefit=True)\n",
        "X_new = model.transform(X)\n",
        "X_new.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3168, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snkB6vwBGJ-b",
        "outputId": "e61fb5ac-6fdc-4a97-b84d-6261572de939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn.fit(model.transform(X_train), y_train)\n",
        "nb = BernoulliNB()\n",
        "nb.fit(model.transform(X_train), y_train)\n",
        "\n",
        "print(\"KNN\")\n",
        "print(classification_report(knn.predict(model.transform(X_test)), y_test))\n",
        "print(\"Naive Bayesian\")\n",
        "print(classification_report(nb.predict(model.transform(X_test)), y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.99      0.97      0.98       394\n",
            "        male       0.97      0.99      0.98       398\n",
            "\n",
            "    accuracy                           0.98       792\n",
            "   macro avg       0.98      0.98      0.98       792\n",
            "weighted avg       0.98      0.98      0.98       792\n",
            "\n",
            "Naive Bayesian\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       1.00      0.49      0.66       792\n",
            "        male       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.49       792\n",
            "   macro avg       0.50      0.24      0.33       792\n",
            "weighted avg       1.00      0.49      0.66       792\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzxQ8F8iGJ-k"
      },
      "source": [
        "# What do you get from the above classification?\n",
        "\n",
        "Note that having a precision of 97% purely based on selecting the right features is pretty good!\n",
        "\n",
        "A tree based approach seems to yield some fruit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxi3aO9BGJ-k",
        "outputId": "9786925c-486d-4405-e0a5-e60c10c5d0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        }
      },
      "source": [
        "# Visualize the differences\\\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.Series(dict(zip(X.columns, clf.feature_importances_))).plot.bar()\n",
        "plt.show()\n",
        "pd.Series(dict(zip(X.columns, lsvc.coef_[0]))).plot.bar()\n",
        "plt.show()\n",
        "# view.plot.bar()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RolJD438GJ-o"
      },
      "source": [
        "# What do you learn from this?\n",
        "\n",
        "Looking at the plots above what can you learn? What is the most important feature as it relates to gendered voice given tree classifications?\n",
        "\n",
        "What is the most important coefficient for a linear model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0K6ii8tGJ-p"
      },
      "source": [
        "# Feature Transformation\n",
        "\n",
        "Above we selected features that are most likely to help us classify. But what if we don't want to give up on features? What if we want to keep it all?\n",
        "\n",
        "There are generally a few directions we can go in.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition\n",
        "\n",
        "Here's a bunch of options ranked from simplistic to state of the art\n",
        "\n",
        "* PCA (Principal Component Analysis)\n",
        "* ICA (Independent Component Analysis)\n",
        "* UMAP (Uniform Manifold Approximation and Projection for Dimension Reduction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dmyEMxUGJ-p",
        "outputId": "346ffa62-b7b1-47ef-f2e5-e3cb8291961d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "# PCA (usually 2 components is a start)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "model = PCA(n_components=4)\n",
        "model.fit(X)\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(model.transform(X_train), y_train)\n",
        "nb = BernoulliNB()\n",
        "nb.fit(model.transform(X_train), y_train)\n",
        "\n",
        "print(\"KNN\")\n",
        "print(classification_report(knn.predict(model.transform(X_test)), y_test))\n",
        "print(\"Naive Bayesian\")\n",
        "print(classification_report(nb.predict(model.transform(X_test)), y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.66      0.71      0.69       363\n",
            "        male       0.74      0.70      0.72       429\n",
            "\n",
            "    accuracy                           0.70       792\n",
            "   macro avg       0.70      0.70      0.70       792\n",
            "weighted avg       0.71      0.70      0.70       792\n",
            "\n",
            "Naive Bayesian\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.59      0.72      0.65       317\n",
            "        male       0.78      0.66      0.72       475\n",
            "\n",
            "    accuracy                           0.69       792\n",
            "   macro avg       0.68      0.69      0.68       792\n",
            "weighted avg       0.70      0.69      0.69       792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaPKqskNGJ-t",
        "outputId": "818f3f2f-bfc1-44c0-fd4e-0f3143ad718f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "from sklearn.decomposition import FastICA\n",
        "\n",
        "model = FastICA(4)\n",
        "model.fit(X)\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(model.transform(X_train), y_train)\n",
        "nb = BernoulliNB()\n",
        "nb.fit(model.transform(X_train), y_train)\n",
        "\n",
        "print(\"KNN\")\n",
        "print(classification_report(knn.predict(model.transform(X_test)), y_test))\n",
        "print(\"Naive Bayesian\")\n",
        "print(classification_report(nb.predict(model.transform(X_test)), y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.73      0.74      0.73       381\n",
            "        male       0.75      0.74      0.75       411\n",
            "\n",
            "    accuracy                           0.74       792\n",
            "   macro avg       0.74      0.74      0.74       792\n",
            "weighted avg       0.74      0.74      0.74       792\n",
            "\n",
            "Naive Bayesian\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.78      0.61      0.68       492\n",
            "        male       0.53      0.71      0.61       300\n",
            "\n",
            "    accuracy                           0.65       792\n",
            "   macro avg       0.65      0.66      0.64       792\n",
            "weighted avg       0.68      0.65      0.65       792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tdDnYeJGJ-2",
        "outputId": "c824c19f-d941-4805-9f11-612623d5b5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "import umap\n",
        "\n",
        "model = umap.UMAP()\n",
        "model.fit(X)\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(model.transform(X_train), y_train)\n",
        "nb = BernoulliNB()\n",
        "nb.fit(model.transform(X_train), y_train)\n",
        "\n",
        "print(\"KNN\")\n",
        "print(classification_report(knn.predict(model.transform(X_test)), y_test))\n",
        "print(\"Naive Bayesian\")\n",
        "print(classification_report(nb.predict(model.transform(X_test)), y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.66      0.65      0.65       394\n",
            "        male       0.66      0.67      0.66       398\n",
            "\n",
            "    accuracy                           0.66       792\n",
            "   macro avg       0.66      0.66      0.66       792\n",
            "weighted avg       0.66      0.66      0.66       792\n",
            "\n",
            "Naive Bayesian\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.84      0.60      0.70       546\n",
            "        male       0.45      0.74      0.56       246\n",
            "\n",
            "    accuracy                           0.64       792\n",
            "   macro avg       0.65      0.67      0.63       792\n",
            "weighted avg       0.72      0.64      0.65       792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p85rBzsGJ-7"
      },
      "source": [
        "# Not the best results but what did we learn?\n",
        "\n",
        "In the above sections we tried out selecting better features and even transforming the existing features into a new matrix. The best approach from above was using KNN with Tree based selection. While that's true, can we utilize a better algorithm to get even better results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3syV3i8GJ-8"
      },
      "source": [
        "# Ensemble Learning\n",
        "\n",
        "In general ensemble learning shows up either as bagging, or boosting, sometimes bayesian selection.\n",
        "\n",
        "In this section we'll show the results of Bagging first and then Random Forests and then Boosting using XgBoost (state of the art)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zuozHkGGJ-8",
        "outputId": "27db5366-1556-4b1b-aa12-110d742fcf13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = BaggingClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(classification_report(model.predict(X_test), y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.98      0.96      0.97       394\n",
            "        male       0.97      0.98      0.97       398\n",
            "\n",
            "    accuracy                           0.97       792\n",
            "   macro avg       0.97      0.97      0.97       792\n",
            "weighted avg       0.97      0.97      0.97       792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahHAe53fGJ_A"
      },
      "source": [
        "# Great results! can we do better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRfBSDjJGJ_A",
        "outputId": "cd7daa8c-408d-4712-e83e-bd207a45101d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('feature_selection', SelectFromModel(LinearSVC(C=0.01))),\n",
        "    ('bagger', BaggingClassifier())])\n",
        "\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "print(classification_report(pipe.predict(X_test), y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.99      0.96      0.97       403\n",
            "        male       0.96      0.99      0.97       389\n",
            "\n",
            "    accuracy                           0.97       792\n",
            "   macro avg       0.97      0.97      0.97       792\n",
            "weighted avg       0.97      0.97      0.97       792\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CozxnkVaGJ_F",
        "outputId": "d1eb3685-2866-4e5f-f175-650685683b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('feature_transformer', FastICA(15)),\n",
        "    ('bagger', BaggingClassifier())])\n",
        "\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "print(classification_report(pipe.predict(X_test), y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.98      0.96      0.97       396\n",
            "        male       0.96      0.98      0.97       396\n",
            "\n",
            "    accuracy                           0.97       792\n",
            "   macro avg       0.97      0.97      0.97       792\n",
            "weighted avg       0.97      0.97      0.97       792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9UihFVNGJ_J"
      },
      "source": [
        "# There are endless possibilities\n",
        "\n",
        "Note that this is an area of research: AutoML. Basically there's so many options, so many possibilities it'd take forever to explain them all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMuU7LX8GJ_J",
        "outputId": "b36d9616-221a-448e-9413-1b2a37810d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(classification_report(clf.predict(X_test), y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.99      0.97      0.98       397\n",
            "        male       0.97      0.99      0.98       395\n",
            "\n",
            "    accuracy                           0.98       792\n",
            "   macro avg       0.98      0.98      0.98       792\n",
            "weighted avg       0.98      0.98      0.98       792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXMwMG3SGJ_O",
        "outputId": "f1bc82e3-d410-4715-c54f-1b875e3081f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "clf = XGBClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(classification_report(clf.predict(X_test), y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.99      0.97      0.98       396\n",
            "        male       0.97      0.99      0.98       396\n",
            "\n",
            "    accuracy                           0.98       792\n",
            "   macro avg       0.98      0.98      0.98       792\n",
            "weighted avg       0.98      0.98      0.98       792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4lcZF9tGJ_R",
        "outputId": "1e8e9101-a03c-41ed-cb8c-247804641b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('transformer', PCA(10)),\n",
        "    ('estimator', XGBClassifier())\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(classification_report(pipe.predict(X_test), y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.98      0.96      0.97       395\n",
            "        male       0.96      0.98      0.97       397\n",
            "\n",
            "    accuracy                           0.97       792\n",
            "   macro avg       0.97      0.97      0.97       792\n",
            "weighted avg       0.97      0.97      0.97       792\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}